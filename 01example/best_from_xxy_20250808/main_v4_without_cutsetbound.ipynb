{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pentropy_main import *\n",
    "import itertools\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import defaultdict, Counter\n",
    "print = print_\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = Region.empty()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region.exprs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "优化后的对称性化简办法 迭代版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "N = 6\n",
    "K = 4\n",
    "point_num = 12 # 采样点密度\n",
    "generate_size = 30\n",
    "subset_size = 30\n",
    "comb_size = 30\n",
    "user_perm = list(itertools.permutations(range(1, K + 1)))\n",
    "file_perm = list(itertools.permutations(range(1, N + 1)))\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate all random variables, stores in single_vars\n",
    "single_vars = [] # 单变量=W+Z+reduced_X\n",
    "Wrvs = [] # 原始W变量，也可以理解为一个全部W组成的单变量\n",
    "W_combinations = [] # W变量组合之后的全部变量\n",
    "Wrvs_cons = [] # 对前面的全部组合进行对称化去除之后的W_combinations\n",
    "vars = [] # 用来在cutsetbound中使用的对象\n",
    "necessary_vars = [] # 后面迭代的时候使用的。\n",
    "\n",
    "for i in range(1, N+1):\n",
    "    single_vars.append(\"W\" + str(i))\n",
    "    Wrvs.append(\"W\" + str(i))\n",
    "for i in range(1, K+1):\n",
    "    single_vars.append(\"Z\" + str(i))\n",
    "vars.append(Wrvs)\n",
    "\n",
    "X_combinations = [\"X\" + item for item in Iutils.generate_combinations(N, K)]\n",
    "X_combinations = get_reduced_X_combination(N,K,False)\n",
    "\n",
    "Xrvs_cons = Iutils.symmetry_vars(user_perm,file_perm,X_combinations)\n",
    "\n",
    "for item in X_combinations:\n",
    "    single_vars.append(item)\n",
    "for var in single_vars:\n",
    "    # vars.append([var])\n",
    "    necessary_vars.append([var])\n",
    "necessary_vars.append(Wrvs)\n",
    "for r in range(N+1): # 这里似乎有点冗余，但是问题不大。\n",
    "    # 生成指定长度的所有组合\n",
    "    combos = itertools.combinations(Wrvs, r+1)\n",
    "    for combo in combos:\n",
    "        W_combinations.append(list(combo))\n",
    "Wrvs_cons = Iutils.symmetry_vars(user_perm,file_perm,W_combinations)\n",
    "print(Wrvs_cons)\n",
    "print(single_vars)\n",
    "Wkey = ','.join(sorted(Wrvs, key=Iutils.sort_key))\n",
    "print(Wkey)\n",
    "print(Xrvs_cons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regions,entropydict = create_cutset_bound(N,K,user_perm,file_perm,Wkey,vars)\n",
    "# entropydict_all = copy.deepcopy(entropydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "necessary_vars = [] # 单变量+W_all变量\n",
    "vars = [] # 上面的necessary_vars+generated_sets，作为Z用于生成不等式；变量集合，元素为列表，一个列表对应一个联合熵，列表元素为字符串\n",
    "entropydict = EntropyEqDict()\n",
    "index = 0\n",
    "episode = 0\n",
    "\n",
    "for var in single_vars:\n",
    "    vars.append([var])\n",
    "    necessary_vars.append([var])\n",
    "# necessary_vars = Iutils.symmetry_vars(N,K,vars)\n",
    "necessary_vars.append(Wrvs)\n",
    "vars.append(Wrvs)\n",
    "\n",
    "sets = Iutils.generate_random_subsets(single_vars,subset_size,2,episode+4)\n",
    "# print(sets)\n",
    "vars += sets\n",
    "print(necessary_vars)\n",
    "print(vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expand_vars = vars[:]\n",
    "\n",
    "combs,combinations = Iutils.generate_combs(single_vars,comb_size)\n",
    "Iutils.preprocessing_combs(vars,single_vars,expand_vars,combs)    \n",
    "\n",
    "entropydict = EntropyEqDict()\n",
    "entropydict_all = EntropyEqDict()\n",
    "\n",
    "print(len(expand_vars))\n",
    "print(expand_vars)\n",
    "Iutils.symmetrize_by_dict_simple(N,K,expand_vars,entropydict_all)\n",
    "# Iutils.symmetrize_by_dict(user_perm,file_perm,expand_vars,entropydict,entropydict_all)\n",
    "print(len(entropydict.redict))\n",
    "\n",
    "Iutils.problem_constraints_process(N,K,Wkey,entropydict_all)\n",
    "entropydict_all.regenerate_keys()\n",
    "\n",
    "for var in expand_vars:\n",
    "    var_str = \",\".join(sorted(var,key=Iutils.sort_key))\n",
    "    entropydict[var_str] = entropydict_all.get(var_str)\n",
    "entropydict.regenerate_keys()\n",
    "\n",
    "print(len(entropydict.redict))\n",
    "print(entropydict.redict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate inequalities\n",
    "regions = Region.empty() # 这里是初始化为empty的region，后续更新为cutsetbound\n",
    "Iutils.generate_inequalities_combs(vars,entropydict,regions,combinations) # 打印的是返回值Ixyz_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(regions.exprs))\n",
    "for expr in regions.exprs:\n",
    "    expr.sort_terms()\n",
    "    print(expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the constranits matrix\n",
    "ent_num = len(entropydict.redict) + 3\n",
    "ine_constraints = Regions2Matrix(entropydict,regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem constraints\n",
    "ine_constraints,prob_cons_num = AddProblemConstrains2Matrix(Xrvs_cons,Wrvs_cons,entropydict,ent_num,ine_constraints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ine_constraints = np.array(ine_constraints)\n",
    "print(ine_constraints.shape)\n",
    "ine_constraints = ine_constraints.astype(np.float64)\n",
    "expr_num = ine_constraints.shape[0] - 1 # 不等式数量\n",
    "ent_num = ine_constraints.shape[1] - 1 # 减之前用于生成矩阵，减之后就是实际的熵变量数量\n",
    "\n",
    "ori_obj_coef = np.zeros(ent_num)\n",
    "ori_obj_coef[-1] = 1 # M，R，F\n",
    "print(ent_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solve problem\n",
    "plot_data = [] # (M_value,optimal_value)\n",
    "effective_idx_gurobi = [] # index from gurobi\n",
    "all_eff_indx = set() # 缩减之后的有效索引\n",
    "result_slope = []# \n",
    "ori_slope = []\n",
    "M_space = np.linspace(0,N,point_num*N+1)\n",
    "dual_value = [] # 每个M下的对偶变量的值\n",
    "effective_idx_cut = [] # 缩减之后的有效索引\n",
    "# print(M_space)\n",
    "for M_value in M_space:\n",
    "    # 根据M_value更新约束矩阵，添加等式约束\n",
    "    ine_constraints = list(ine_constraints[:-1])\n",
    "    row = [0] * (ent_num + 1)\n",
    "    row[-3] = 1\n",
    "    row[-1] = M_value\n",
    "    ine_constraints.append(row)\n",
    "    ine_constraints = np.array(ine_constraints)\n",
    "    \n",
    "    # print(\"ine_constraints\")\n",
    "    # print(ine_constraints)\n",
    "    # print(\"ori_obj_coef\",ori_obj_coef)\n",
    "\n",
    "    # # 更新对偶问题约束矩阵\n",
    "    expr_num = ine_constraints.shape[0] - 1\n",
    "    trans_ine_cons = ine_constraints.T[:-1] # 对偶问题的约束矩阵 是原约束矩阵的转置\n",
    "    dual_obj_coef = ine_constraints[:,-1] # 原约束的常量 是对偶问题目标函数的系数\n",
    "    trans_ine_cons = np.hstack((trans_ine_cons, ori_obj_coef.T.reshape(-1, 1))) # 原目标函数的系数，是对偶问题约束的常量\n",
    "    # print(\"shape\",trans_ine_cons.shape)\n",
    "    # print(\"trans_ine_cons\")\n",
    "    # print(trans_ine_cons)\n",
    "    # print(\"dual_obj_coef\",dual_obj_coef)\n",
    "\n",
    "    # 求解原LP问题\n",
    "    result,effective_idx_gurobi = gurobi_solver(effective_idx_gurobi,ori_obj_coef,ent_num,ine_constraints,regions)\n",
    "    if type(result) == list:\n",
    "        bad = Region.empty()\n",
    "        for ine in result:\n",
    "            idx = int(ine[1:])\n",
    "            print(f\"type:{type(idx)},value:{idx}\")\n",
    "            terms = []\n",
    "            row = ine_constraints[idx]\n",
    "            for i in range(len(row) - 1):\n",
    "                coef = row[i]\n",
    "                if coef != 0:\n",
    "                    if entropydict.get_keys_by_value(i) != None:\n",
    "                        term_x = entropydict.get_keys_by_value(i)[0]\n",
    "                        var_str = term_x.split(\",\")\n",
    "                        if var_str not in vars:\n",
    "                            vars.append(var_str) # 添加有效不等式中的变量\n",
    "                        term_x = Comp.jes(term_x)\n",
    "                        term = Term(x=[term_x.copy()],coef=int(coef),termtype=TermType.H)\n",
    "                        terms.append(term) \n",
    "            expr = Expr(terms, eqtype=\"ge\", value=row[-1])\n",
    "            expr.sort_terms()\n",
    "            # print(\"expr\",expr)\n",
    "            bad.append_expr(expr)\n",
    "        for expr in bad.exprs:\n",
    "            print(expr)\n",
    "   \n",
    "    # 求解对偶LP问题\n",
    "    if result != 0:\n",
    "        solution_values, effective_idx_dual = dual_solver(expr_num,dual_obj_coef,trans_ine_cons,prob_cons_num)\n",
    "        if solution_values is not None:\n",
    "            dual_value.append(list(solution_values.values()))\n",
    "\n",
    "        # print(\"effective_indices\",effective_idx_dual)\n",
    "        if effective_idx_dual is not None:\n",
    "            all_eff_indx = all_eff_indx.union(set(effective_idx_dual))\n",
    "        effective_idx_dual = sorted(list(all_eff_indx))\n",
    "    \n",
    "    plot_data.append((M_value, result))\n",
    "if len(dual_value) > 0:\n",
    "    effective_idx_cut = find_min_effective_indices(dual_value,regions)\n",
    "    # print(\"dual\")\n",
    "    # print(dual_value)\n",
    "    print(f\"dual:{len(effective_idx_dual)}\")\n",
    "    print(effective_idx_dual)\n",
    "    print(f\"gurobi:{len(effective_idx_gurobi)}\")\n",
    "    print(effective_idx_gurobi)\n",
    "    print(f\"cut:{len(effective_idx_cut)}\")\n",
    "    print(effective_idx_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "\n",
    "Iutils.plot_inner_bound(N,K)\n",
    "# plot the calculation result\n",
    "x = [item[0] for item in plot_data]\n",
    "y = [item[1] for item in plot_data]\n",
    "result_slope = Iutils.compute_slopes(x,y)\n",
    "point_x = []\n",
    "point_y = []\n",
    "for i in range(1,len(result_slope)):\n",
    "    if result_slope[i-1] != result_slope[i]:\n",
    "        point_x.append(x[i])\n",
    "        point_y.append(y[i])\n",
    "plt.scatter(point_x,point_y,color='red')\n",
    "\n",
    "for xi, yi in zip(point_x, point_y):\n",
    "    label = f\"({round(xi,3)}, {round(yi,3)})\"\n",
    "    plt.annotate(label,  \n",
    "                (xi, yi),  \n",
    "                textcoords=\"offset points\",  \n",
    "                xytext=(30, 5),  \n",
    "                ha='center') \n",
    "plt.plot(x, y, color='red', linewidth=3, label='computed outer bound')\n",
    "Iutils.plot_cutset_bound(N,K,point_num)\n",
    "\n",
    "plt.xlim(left=0)\n",
    "plt.ylim(bottom=0)\n",
    "plt.xlabel(\"M\")\n",
    "plt.ylabel(\"R\")\n",
    "plt.legend()\n",
    "plt.title(f\"Case(N,K)=({N},{K}),episode0\\nvars:{len(vars)},cons:{ine_constraints.shape}\")\n",
    "plt.show()\n",
    "print(\"from start to now: \",time.time()-start_time,\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode = 0\n",
    "oriall_vars = [] # 存放所有已经生成过的变量\n",
    "same_times = 0\n",
    "stop_same_time = 5\n",
    "effctive_vars_last = []\n",
    "while episode < 500:\n",
    "    episode += 1\n",
    "    # print(\"episode\",episode)\n",
    "    # print(ori_slope)\n",
    "    # print(result_slope)\n",
    "    if ori_slope ==  result_slope:\n",
    "        same_times += 1\n",
    "    else:\n",
    "        same_times = 0\n",
    "    if same_times == stop_same_time:\n",
    "        break\n",
    "    # print(\"oriall vars\",len(oriall_vars))\n",
    "    # print(\"same times\",same_times)\n",
    "    # print(entropydict_all.eqdict)\n",
    "    # 更新regions、vars\n",
    "    # print(\"1.更新regions、vars\")\n",
    "    # print(\"number of effective exprs:\",len(effective_idx_cut))\n",
    "    # print(effective_indices)\n",
    "    effective_constraints = [ine_constraints[i] for i in effective_idx_cut]\n",
    "    regions = Region.empty() # 更新regions\n",
    "    ori_vars = vars[:]\n",
    "    oriall_vars += vars[:]\n",
    "    # entropydict_all = entropydict.copy()\n",
    "    vars = []\n",
    "    effective_vars = []\n",
    "    effective_idx_cut = []\n",
    "    add_vars = set()\n",
    "    del_vars = set()\n",
    "    index = 0\n",
    "    count_dict = {}\n",
    "    # regions = cutset_regions.copy()\n",
    "    # print(\"dict\",regions.exprdict)\n",
    "    for row in effective_constraints:\n",
    "        terms = []\n",
    "        term_list = []\n",
    "        for i in range(len(row) - 1):\n",
    "            coef = row[i]\n",
    "            if coef != 0:\n",
    "                if entropydict.get_keys_by_value(i) != None:\n",
    "                    term_x = entropydict.get_keys_by_value(i)[0]\n",
    "                    var_str = term_x.split(\",\")\n",
    "                    if term_x in count_dict:\n",
    "                        count_dict[term_x] += 1\n",
    "                    else:\n",
    "                        count_dict[term_x] = 1\n",
    "                    if var_str not in vars:\n",
    "                        vars.append(var_str) # 添加有效不等式中的变量\n",
    "                    term_list.append(coef)\n",
    "                    term_list.append(term_x)\n",
    "                    term_x = Comp.jes(term_x)\n",
    "                    term = Term(x=[term_x.copy()],coef=int(coef),termtype=TermType.H)\n",
    "                    terms.append(term)\n",
    "        # print(term_list)\n",
    "        # x_vars, y_vars, z_vars = extract_single_var_conditional(term_list)\n",
    "        # print(f\"x_vars:{x_vars}, y_vars:{y_vars}, z_vars:{z_vars}\")\n",
    "        expr = Expr(terms, eqtype=\"ge\", value=row[-1])\n",
    "        expr.sort_terms()\n",
    "        # print(\"expr\",expr)\n",
    "        regions.append_expr(expr)\n",
    "    for expr in regions.exprs:\n",
    "        pass\n",
    "        # print(expr)\n",
    "        \n",
    "       \n",
    "    effective_vars = vars[:]\n",
    "    add_vars = set(map(tuple, effective_vars)) - set(map(tuple, effctive_vars_last))\n",
    "    del_vars = set(map(tuple, effctive_vars_last)) - set(map(tuple, effective_vars))\n",
    "    effctive_vars_last = vars[:]\n",
    "    \n",
    "    # print(f\"add vars:{add_vars}\")\n",
    "    # print(f\"del vars:{del_vars}\")\n",
    "\n",
    "    # print(\"effective vars\",vars)\n",
    "    # print(\"len of effecitve vars\",len(vars))\n",
    "    count_dict = sorted(count_dict.items(), key=lambda item: item[1],reverse=True)\n",
    "    count_dict = dict(count_dict)\n",
    "    # print(count_dict)\n",
    "\n",
    "    # 生成新vars\n",
    "    # print(\"2.生成新vars\")\n",
    "    # 方式1：effective vars的子集\n",
    "    # generate_vars = Iutils.generate_random_subsets(effective_vars,generate_size,2,episode+3)\n",
    "    \n",
    "    # 方式2：ori vars的交并集\n",
    "    generate_vars = []\n",
    "    for i in range(len(ori_vars)):\n",
    "        for j in range(i + 1, len(ori_vars)):\n",
    "            union = list(set(ori_vars[i]) | set(ori_vars[j]))\n",
    "            if len(union) <= episode+1:\n",
    "                # print(\"lenunion\",len(union))\n",
    "                union.sort()\n",
    "                generate_vars.append(union)\n",
    "            ins = list(set(ori_vars[i]) & set(ori_vars[j]))\n",
    "            if ins:\n",
    "                ins.sort()\n",
    "                generate_vars.append(ins)\n",
    "\n",
    "    # 方式3：effctive vars的交并集\n",
    "    # generate_vars = []\n",
    "    # for i in range(len(effective_vars)):\n",
    "    #     for j in range(i + 1, len(effective_vars)):\n",
    "    #         union = list(set(effective_vars[i]) | set(effective_vars[j]))\n",
    "    #         if len(union) <= episode+1:\n",
    "    #             # print(\"lenunion\",len(union))\n",
    "    #             union.sort()\n",
    "    #             generate_vars.append(union)\n",
    "    #         ins = list(set(effective_vars[i]) & set(effective_vars[j]))\n",
    "    #         if ins:\n",
    "    #             ins.sort()\n",
    "    #             generate_vars.append(ins)\n",
    "    \n",
    "    if generate_size > len(generate_vars):\n",
    "        generate_size = len(generate_vars)\n",
    "    random_indices = np.random.choice(len(generate_vars), size=generate_size, replace=False)\n",
    "    selected_vars = [generate_vars[i] for i in random_indices]\n",
    "    # selected_vars = generate_vars[:]\n",
    "\n",
    "    for var in selected_vars:\n",
    "        if var not in vars:\n",
    "            vars.append(var)\n",
    "    # print(len(vars))\n",
    "    # for var in single_vars:\n",
    "    #     if [var] not in vars:\n",
    "    #         vars.append([var])\n",
    "    # print(len(vars))\n",
    "\n",
    "\n",
    "    # 随机引入子集\n",
    "    result_subsets = Iutils.generate_random_subsets(single_vars, subset_size, 2, episode+4)\n",
    "    for subset in result_subsets:\n",
    "        if subset not in vars and subset not in oriall_vars:\n",
    "            vars.append(subset)\n",
    "\n",
    "    # 显示vars构成\n",
    "    # print(\"ori vars\",len(ori_vars))\n",
    "    # print(ori_vars)\n",
    "    # print(\"generate vars\",len(generate_vars))\n",
    "    # print(generate_vars)\n",
    "    # print(\"selected vars\",len(selected_vars))\n",
    "    # print(selected_vars)\n",
    "    # print(\"random vars\",len(result_subsets))\n",
    "    # print(result_subsets)\n",
    "    # print(\"number of varibles:\",len(vars))\n",
    "\n",
    "    # 对vars进行封闭集和对称性处理，生成entropydict\n",
    "    # print(\"3.对vars进行封闭集和对称性处理，生成entropydict\")\n",
    "    expand_vars = vars[:]\n",
    "    combs,combinations = Iutils.generate_combs(single_vars,comb_size)\n",
    "    Iutils.preprocessing_combs(vars,single_vars,expand_vars,combs)\n",
    "    for var in necessary_vars:\n",
    "        if var not in expand_vars:\n",
    "            expand_vars.append(var)\n",
    "    # print(\"before symmetrize num of expanded vars:\",len(expand_vars))\n",
    "    entropydict = EntropyEqDict()\n",
    "    # Xrvs_cons = []\n",
    "    # Wrvs_cons = []\n",
    "    # print(\"all_before_eqdict\",len(entropydict_all.eqdict))\n",
    "    # print(\"all_before_redict\",len(entropydict_all.redict))\n",
    "    # Iutils.symmetrize_by_dict(user_perm,file_perm,expand_vars,entropydict,entropydict_all)\n",
    "    Iutils.symmetrize_by_dict_simple(N,K,expand_vars,entropydict_all)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Iutils.symmetrize_simple(N,K,expand_vars,entropydict)\n",
    "    # print(\"after symmetreize num of expanded vars:\",len(entropydict.redict))\n",
    "    # print(\"all_after_eq\",len(entropydict_all.eqdict))\n",
    "    # print(\"all_after_re\",len(entropydict_all.redict))\n",
    "    # Iutils.symmetrize(user_perm,file_perm,expand_vars,entropydict,Xrvs_cons,Wrvs_cons)\n",
    "    # print(entropydict)\n",
    "\n",
    "    # 问题约束\n",
    "    # print(\"4.问题约束\")\n",
    "    Iutils.problem_constraints_process(N,K,Wkey,entropydict_all)\n",
    "    entropydict_all.regenerate_keys()\n",
    "    for var in expand_vars:\n",
    "        var_str = \",\".join(sorted(var,key=Iutils.sort_key))\n",
    "        entropydict[var_str] = entropydict_all.get(var_str)\n",
    "    entropydict.regenerate_keys()\n",
    "    # print(entropydict.redict)\n",
    "    # print(\"entropydictall\",len(entropydict_all.redict))\n",
    "    # print(\"number of problem variebles\",len(entropydict.redict))\n",
    "    # print(\"number of all the variebles\",len(entropydict.eqdict))\n",
    "\n",
    "    # 生成不等式集，并合并相同不等式\n",
    "    # print(\"5.生成不等式集，并合并相同不等式\")\n",
    "    Iutils.generate_inequalities_combs(vars,entropydict,regions,combinations)\n",
    "    # print(\"before reducing\",len(regions.exprs))\n",
    "    regions.reduce_redundant_expr()\n",
    "    # print(\"number of exprs\",len(regions.exprs))\n",
    "    # ------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    # 生成不等式矩阵\n",
    "    # print(\"6.生成不等式矩阵\")\n",
    "    ent_num = len(entropydict.redict) + 3\n",
    "    ine_constraints = Regions2Matrix(entropydict,regions)\n",
    "    \n",
    "    # additional constraints\n",
    "    ine_constraints,prob_cons_num = AddProblemConstrains2Matrix(Xrvs_cons,Wrvs_cons,entropydict,ent_num,ine_constraints)\n",
    "    ent_num -= 1 # 实际变量数量\n",
    "    \n",
    "\n",
    "    # 问题求解\n",
    "    plot_data = []\n",
    "    effective_idx_gurobi = []\n",
    "    all_eff_indx = set()\n",
    "    result_slope = []\n",
    "    ori_slope = []\n",
    "    M_space = np.linspace(0,N,point_num*N+1)\n",
    "    dual_value = []\n",
    "    # print(M_space)\n",
    "    t_solve = 0\n",
    "    # print(\"shape of ine_constraints\",ine_constraints.shape)\n",
    "    for M_value in M_space:\n",
    "        s = time.perf_counter()\n",
    "        # 根据M_value更新约束矩阵，添加等式约束\n",
    "        ine_constraints = list(ine_constraints[:-1])\n",
    "        row = [0] * (ent_num + 1)\n",
    "        row[-3] = 1\n",
    "        row[-1] = M_value\n",
    "        ine_constraints.append(row)\n",
    "\n",
    "        ine_constraints = np.array(ine_constraints)\n",
    "        if M_value == 0:\n",
    "            pass\n",
    "            # print(\"shape of ine_constraints\",ine_constraints.shape)\n",
    "        ine_constraints = ine_constraints.astype(np.float64)\n",
    "\n",
    "        ori_obj_coef = np.zeros(ent_num)\n",
    "        ori_obj_coef[-1] = 1\n",
    "        # print(\"ine_constraints\")\n",
    "        # print(ine_constraints)\n",
    "        # print(\"ori_obj_coef\",ori_obj_coef)\n",
    "\n",
    "        # # 更新对偶问题约束矩阵\n",
    "        expr_num = ine_constraints.shape[0] - 1\n",
    "        trans_ine_cons = ine_constraints.T[:-1] # 对偶问题的约束矩阵 是原约束矩阵的转置\n",
    "        dual_obj_coef = ine_constraints[:,-1] # 原约束的常量 是对偶问题目标函数的系数\n",
    "        trans_ine_cons = np.hstack((trans_ine_cons, ori_obj_coef.T.reshape(-1, 1))) # 原目标函数的系数，是对偶问题约束的常量\n",
    "        # print(\"shape\",trans_ine_cons.shape)\n",
    "        # print(trans_ine_cons)\n",
    "        # print(\"dual_obj_coef\",dual_obj_coef)\n",
    "\n",
    "        # 求解原LP问题\n",
    "        result,effective_idx_gurobi = gurobi_solver(effective_idx_gurobi,ori_obj_coef,ent_num,ine_constraints,regions)\n",
    "        if type(result) == list:\n",
    "            bad = Region.empty()\n",
    "            for ine in result:\n",
    "                idx = int(ine[1:])\n",
    "                # print(f\"type:{type(idx)},value:{idx}\")\n",
    "                terms = []\n",
    "                row = ine_constraints[idx]\n",
    "                for i in range(len(row) - 1):\n",
    "                    coef = row[i]\n",
    "                    if coef != 0:\n",
    "                        if entropydict.get_keys_by_value(i) != None:\n",
    "                            term_x = entropydict.get_keys_by_value(i)[0]\n",
    "                            var_str = term_x.split(\",\")\n",
    "                            if term_x in count_dict:\n",
    "                                count_dict[term_x] += 1\n",
    "                            else:\n",
    "                                count_dict[term_x] = 1\n",
    "                            if var_str not in vars:\n",
    "                                vars.append(var_str) # 添加有效不等式中的变量\n",
    "                            term_x = Comp.jes(term_x)\n",
    "                            term = Term(x=[term_x.copy()],coef=int(coef),termtype=TermType.H)\n",
    "                            terms.append(term) \n",
    "                expr = Expr(terms, eqtype=\"ge\", value=row[-1])\n",
    "                expr.sort_terms()\n",
    "                # print(\"expr\",expr)\n",
    "                bad.append_expr(expr)\n",
    "            for expr in bad.exprs:\n",
    "                pass\n",
    "                # print(expr)\n",
    "\n",
    "        elif result > 0:\n",
    "            # 求解对偶LP问题\n",
    "            solution_values, effective_idx_dual = dual_solver(expr_num,dual_obj_coef,trans_ine_cons,prob_cons_num)\n",
    "            if solution_values is not None:\n",
    "                dual_value.append(list(solution_values.values()))\n",
    "\n",
    "            # print(\"effective_indices\",effective_idx_dual)\n",
    "            if effective_idx_dual is not None:\n",
    "                all_eff_indx = all_eff_indx.union(set(effective_idx_dual))\n",
    "            effective_idx_dual = sorted(list(all_eff_indx))\n",
    "        plot_data.append((M_value, result))\n",
    "        e = time.perf_counter()\n",
    "        t = e - s\n",
    "        t_solve += t\n",
    "    # print(\"solve time\",t_solve)\n",
    "    if len(dual_value) > 0:\n",
    "        effective_idx_cut = find_min_effective_indices(dual_value,regions)\n",
    "        # print(f\"dual:{len(effective_idx_dual)}\")\n",
    "        # print(effective_idx_dual)\n",
    "        # print(f\"gurobi:{len(effective_idx_gurobi)}\")\n",
    "        # print(effective_idx_gurobi)\n",
    "        # print(f\"cut:{len(effective_idx_cut)}\")\n",
    "        # print(effective_idx_cut)\n",
    "    # 绘制图像\n",
    "\n",
    "    # plot the cut-set bound\n",
    "    Iutils.plot_cutset_bound(N,K,point_num)\n",
    "    Iutils.plot_inner_bound(N,K)\n",
    "\n",
    "\n",
    "    x = [item[0] for item in plot_data]\n",
    "    y = [item[1] for item in plot_data]\n",
    "    result_slope = Iutils.compute_slopes(x,y)\n",
    "    point_x = []\n",
    "    point_y = []\n",
    "    for i in range(1,len(result_slope)):\n",
    "        if result_slope[i-1] != result_slope[i]:\n",
    "            point_x.append(x[i])\n",
    "            point_y.append(y[i])\n",
    "    plt.scatter(point_x,point_y,color=\"red\")\n",
    "    \n",
    "    for xi, yi in zip(point_x, point_y):\n",
    "        label = f\"({round(xi,3)}, {round(yi,3)})\"\n",
    "        plt.annotate(label,  \n",
    "                    (xi, yi),  \n",
    "                    textcoords=\"offset points\",  \n",
    "                    xytext=(30, 5),  \n",
    "                    ha='center')  \n",
    "    plt.plot(x, y, color='red', linewidth=2, label='computed outer bound')\n",
    "\n",
    "    \n",
    "    plt.xlim(left=0)\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.xlabel(\"M\")\n",
    "    plt.ylabel(\"R\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"Case(N,K)=({N},{K}),episode{episode}\\nX_type={X_combinations}\\nvars:{len(vars)},cons:{ine_constraints.shape}\")\n",
    "    plt.show()\n",
    "    print(\"from start to now: \",time.time()-start_time,\"s\")\n",
    "\n",
    "    print(x)\n",
    "    print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_effective_indices(dual_value):\n",
    "    non_zero_counts = np.count_nonzero(dual_value, axis=1)\n",
    "    single_cut_idx = []\n",
    "    all_cut_idx = set()\n",
    "    if len(dual_value) == 0:\n",
    "        return []\n",
    "    \n",
    "    old_slope = round(dual_value[0][-1],3)\n",
    "    min_row = 0\n",
    "    min_cnt = non_zero_counts[0]\n",
    "    cnt = 0\n",
    "    for idx, row in enumerate(dual_value):\n",
    "        # 当检测到斜率变化时处理前一个分段\n",
    "        if round(row[-1],3) != old_slope:\n",
    "            cnt += 1\n",
    "            print(cnt)\n",
    "            count_dict = {}\n",
    "            current_slope = old_slope  # 保存前一分段的斜率\n",
    "            # 收集前一分段的最小行非零索引\n",
    "            single_cut_idx = []\n",
    "            for i, value in enumerate(dual_value[min_row]):\n",
    "                if value > 0 and i < len(regions.exprs):\n",
    "                    single_cut_idx.append(i)\n",
    "            \n",
    "            print(f\"分段斜率: {current_slope}\\n有效索引: {len(single_cut_idx)},{single_cut_idx}\")\n",
    "            \n",
    "            # 处理约束条件（保持原逻辑）\n",
    "            effective_constraints = [ine_constraints[i] for i in single_cut_idx]\n",
    "            for constraint in effective_constraints:\n",
    "                terms = []\n",
    "                for i in range(len(constraint) - 1):\n",
    "                    coef = constraint[i]\n",
    "                    if coef != 0:\n",
    "                        term_x = entropydict.get_keys_by_value(i)\n",
    "                        if term_x:\n",
    "                            term_x = term_x[0]\n",
    "                            count_dict[term_x] = count_dict.get(term_x, 0) + 1\n",
    "                            term_x = Comp.jes(term_x)\n",
    "                            terms.append(Term(x=[term_x.copy()], coef=int(coef), termtype=TermType.H))\n",
    "                expr = Expr(terms, eqtype=\"ge\", value=constraint[-1])\n",
    "                expr.sort_terms()\n",
    "                new_regions.append_expr(expr)\n",
    "                print(expr)\n",
    "            print(f\"有效变量数量:{len(count_dict)}\")\n",
    "            count_dict = sorted(count_dict.items(), key=lambda item: item[1],reverse=True)\n",
    "            count_dict = dict(count_dict)\n",
    "            print(count_dict)\n",
    "            if cnt == 1:\n",
    "                count_dict_all = count_dict.copy()\n",
    "                # print(\"all\",count_dict_all)\n",
    "            else:\n",
    "                count_dict_all = Counter(count_dict_all)\n",
    "                count_dict_all.update(count_dict)\n",
    "                count_dict_all = dict(count_dict_all)\n",
    "                # print(\"all\",count_dict_all)\n",
    "            all_cut_idx.update(single_cut_idx)\n",
    "            \n",
    "            # 初始化新分段\n",
    "            old_slope = round(row[-1],3)     # 更新为当前行的新斜率\n",
    "            min_cnt = non_zero_counts[idx]\n",
    "            min_row = idx\n",
    "            single_cut_idx = []\n",
    "        \n",
    "        # 更新当前分段的最小行\n",
    "        else:\n",
    "            if non_zero_counts[idx] < min_cnt:\n",
    "                min_cnt = non_zero_counts[idx]\n",
    "                min_row = idx\n",
    "\n",
    "    # 处理最后一个分段\n",
    "    single_cut_idx = []\n",
    "    count_dict = {}\n",
    "    for i, value in enumerate(dual_value[min_row]):\n",
    "        if value > 0 and i < len(regions.exprs):\n",
    "            single_cut_idx.append(i)\n",
    "    cnt += 1\n",
    "    print(cnt)\n",
    "    print(f\"分段斜率: {old_slope}\\n有效索引: {len(single_cut_idx)},{single_cut_idx}\")\n",
    "    \n",
    "    effective_constraints = [ine_constraints[i] for i in single_cut_idx]\n",
    "    for constraint in effective_constraints:\n",
    "        terms = []\n",
    "        for i in range(len(constraint) - 1):\n",
    "            coef = constraint[i]\n",
    "            if coef != 0:\n",
    "                term_x = entropydict.get_keys_by_value(i)\n",
    "                if term_x:\n",
    "                    term_x = term_x[0]\n",
    "                    # var_str = term_x.split(\",\")\n",
    "                    count_dict[term_x] = count_dict.get(term_x, 0) + 1\n",
    "                    # if var_str not in vars:\n",
    "                        # vars.append(var_str)\n",
    "                    term_x = Comp.jes(term_x)\n",
    "                    terms.append(Term(x=[term_x.copy()], coef=int(coef), termtype=TermType.H))\n",
    "        expr = Expr(terms, eqtype=\"ge\", value=constraint[-1])\n",
    "        expr.sort_terms()\n",
    "        new_regions.append_expr(expr)\n",
    "        print(expr)\n",
    "\n",
    "    print(f\"有效变量数量:{len(count_dict)}\")\n",
    "    count_dict = sorted(count_dict.items(), key=lambda item: item[1],reverse=True)\n",
    "    count_dict = dict(count_dict)\n",
    "    print(count_dict) \n",
    "    \n",
    "    count_dict_all = Counter(count_dict_all)\n",
    "    count_dict_all.update(count_dict)\n",
    "    count_dict_all = dict(count_dict_all)\n",
    "    # print(\"all\",count_dict_all)\n",
    "    all_cut_idx.update(single_cut_idx)\n",
    "    \n",
    "    return count_dict_all,sorted(list(all_cut_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(dual_value) > 0:\n",
    "    new_regions = Region.empty()\n",
    "    # print(\"dual value\")\n",
    "    # for row in dual_value:\n",
    "    #     print(row[-1])\n",
    "    count_dict_all, effective_idx_cut = find_min_effective_indices(dual_value)\n",
    "    print(f\"dual:{len(effective_idx_dual)}\")\n",
    "    print(effective_idx_dual)\n",
    "    print(f\"gurobi:{len(effective_idx_gurobi)}\")\n",
    "    print(effective_idx_gurobi)\n",
    "    print(f\"cut:{len(effective_idx_cut)}\")\n",
    "    print(effective_idx_cut)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_factory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
