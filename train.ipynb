{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87274a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# train.py\n",
    "# 开始写代码于20250731\n",
    "# 重构的原因是：\n",
    "#    1. 原代码无法实现multipreocessing\n",
    "#    2. 原代码无法实现GPU训练，改用torch实现目标\n",
    "#    3. 原代码网络通信存在问题，长时间处理会导致问题\n",
    "#    4. 原代码结构十分混乱，具有众多冗余参数，决定对代码进行重构，主要目标是实现multiprecessing\n",
    "#    5. 环境本身也存在问题，但是因为网络通信的原因，通信困难，所以决定直接修改。\n",
    "# 预计时间：本周五之前完成任务。\n",
    "# task:\n",
    "#   1.log——dir还没有建立\n",
    "#   2.converseenv对应的一些全局变量可能存在相互干扰的现象。首先先研究一下是否会干扰，其次需要修改为类的变量。\n",
    "#   3.修改render为\"linux\"和\"windows\"，对应的分别在linux和windows上面运行啊。\n",
    "#   4.直接将numvars修改为ob_dim比较好，免去了来自原始的问题的联合的影响哎。现在没有修改，因为有点害怕改错了。\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bb8f23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished general settings.\n",
      "device:  cpu\n",
      "--- config ---\n",
      "* DBM: True\n",
      "* continue_training: False\n",
      "* task_id: 000\n",
      "* envs_NK: [[2, 2], [2, 3], [3, 2], [3, 3]]\n",
      "* env_config: {'ob_dim': 383}\n",
      "* use_pretrained_model: False\n",
      "* pretrained_model_id: None\n",
      "* new_ineq_num_factor: 0.3\n",
      "* log_dir: 02all_data/000\n",
      "* num_worker: 3\n",
      "* max_epoch_num: 1000\n",
      "* n_directions: 4\n",
      "* evaluate_time: 3\n",
      "* learning_rate: 0.01\n",
      "* gamma: 0.97\n",
      "* std: 0.02\n",
      "* network_param: {'hsize': 64, 'numlayers': 2, 'embed': 100}\n",
      "* device: cpu\n",
      "--- ------ ---\n"
     ]
    }
   ],
   "source": [
    "config = Config(DBM=True)\n",
    "config.set_policy_config()\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "config.set_attention_network_config(device = device)\n",
    "print(\"device: \",device)\n",
    "if config.DBM:\n",
    "    config.print_config()\n",
    "# 建立envs：\n",
    "# envs = make_converse_env(config)\n",
    "# 建立policy：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe400703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92260f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "CUDA Version: 12.4\n",
      "Number of CUDA devices: 1\n",
      "Current Device ID: 0\n",
      "Device Name: NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# 获取CUDA版本号（字符串格式）\n",
    "cuda_version = torch.version.cuda\n",
    "print(f\"CUDA Version: {cuda_version}\")\n",
    "\n",
    "# 获取设备数量（可选）\n",
    "device_count = torch.cuda.device_count()\n",
    "print(f\"Number of CUDA devices: {device_count}\")\n",
    "\n",
    "# 获取当前设备信息（可选）\n",
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current Device ID: {current_device}\")\n",
    "print(f\"Device Name: {torch.cuda.get_device_name(current_device)}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_factory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
